2024-10-15 10:08:52.001218: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0
2024-10-15 10:09:12.990538: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2024-10-15 10:09:13.106398: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcuda.so.1
2024-10-15 10:09:13.557814: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1733] Found device 0 with properties: 
pciBusID: 0000:25:00.0 name: NVIDIA GeForce RTX 3090 computeCapability: 8.6
coreClock: 1.695GHz coreCount: 82 deviceMemorySize: 23.69GiB deviceMemoryBandwidth: 871.81GiB/s
2024-10-15 10:09:13.558401: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1733] Found device 1 with properties: 
pciBusID: 0000:81:00.0 name: NVIDIA GeForce RTX 3090 computeCapability: 8.6
coreClock: 1.695GHz coreCount: 82 deviceMemorySize: 23.69GiB deviceMemoryBandwidth: 871.81GiB/s
2024-10-15 10:09:13.559018: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1733] Found device 2 with properties: 
pciBusID: 0000:c1:00.0 name: NVIDIA GeForce RTX 3090 computeCapability: 8.6
coreClock: 1.695GHz coreCount: 82 deviceMemorySize: 23.69GiB deviceMemoryBandwidth: 871.81GiB/s
2024-10-15 10:09:13.559523: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1733] Found device 3 with properties: 
pciBusID: 0000:e1:00.0 name: NVIDIA GeForce RTX 3090 computeCapability: 8.6
coreClock: 1.695GHz coreCount: 82 deviceMemorySize: 23.69GiB deviceMemoryBandwidth: 871.81GiB/s
2024-10-15 10:09:13.560350: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0
2024-10-15 10:09:14.051408: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcublas.so.11
2024-10-15 10:09:14.051598: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcublasLt.so.11
2024-10-15 10:09:14.426771: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcufft.so.10
2024-10-15 10:09:14.640814: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcurand.so.10
2024-10-15 10:09:15.109727: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcusolver.so.11
2024-10-15 10:09:15.176037: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcusparse.so.11
2024-10-15 10:09:15.214420: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudnn.so.8
2024-10-15 10:09:15.224617: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1871] Adding visible gpu devices: 0, 1, 2, 3
2024-10-15 10:09:15.256713: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0
2024-10-15 10:09:18.373140: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1258] Device interconnect StreamExecutor with strength 1 edge matrix:
2024-10-15 10:09:18.373253: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1264]      0 1 2 3 
2024-10-15 10:09:18.373269: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1277] 0:   N N N N 
2024-10-15 10:09:18.373280: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1277] 1:   N N N N 
2024-10-15 10:09:18.373289: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1277] 2:   N N N N 
2024-10-15 10:09:18.373298: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1277] 3:   N N N N 
2024-10-15 10:09:18.380649: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1418] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 22298 MB memory) -> physical GPU (device: 0, name: NVIDIA GeForce RTX 3090, pci bus id: 0000:25:00.0, compute capability: 8.6)
2024-10-15 10:09:18.384539: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1418] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:1 with 22300 MB memory) -> physical GPU (device: 1, name: NVIDIA GeForce RTX 3090, pci bus id: 0000:81:00.0, compute capability: 8.6)
2024-10-15 10:09:18.385364: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1418] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:2 with 22300 MB memory) -> physical GPU (device: 2, name: NVIDIA GeForce RTX 3090, pci bus id: 0000:c1:00.0, compute capability: 8.6)
2024-10-15 10:09:18.386357: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1418] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:3 with 22300 MB memory) -> physical GPU (device: 3, name: NVIDIA GeForce RTX 3090, pci bus id: 0000:e1:00.0, compute capability: 8.6)
2024-10-15 10:09:18.431673: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1733] Found device 0 with properties: 
pciBusID: 0000:25:00.0 name: NVIDIA GeForce RTX 3090 computeCapability: 8.6
coreClock: 1.695GHz coreCount: 82 deviceMemorySize: 23.69GiB deviceMemoryBandwidth: 871.81GiB/s
2024-10-15 10:09:18.432224: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1733] Found device 1 with properties: 
pciBusID: 0000:81:00.0 name: NVIDIA GeForce RTX 3090 computeCapability: 8.6
coreClock: 1.695GHz coreCount: 82 deviceMemorySize: 23.69GiB deviceMemoryBandwidth: 871.81GiB/s
2024-10-15 10:09:18.432712: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1733] Found device 2 with properties: 
pciBusID: 0000:c1:00.0 name: NVIDIA GeForce RTX 3090 computeCapability: 8.6
coreClock: 1.695GHz coreCount: 82 deviceMemorySize: 23.69GiB deviceMemoryBandwidth: 871.81GiB/s
2024-10-15 10:09:18.433204: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1733] Found device 3 with properties: 
pciBusID: 0000:e1:00.0 name: NVIDIA GeForce RTX 3090 computeCapability: 8.6
coreClock: 1.695GHz coreCount: 82 deviceMemorySize: 23.69GiB deviceMemoryBandwidth: 871.81GiB/s
2024-10-15 10:09:18.436738: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1871] Adding visible gpu devices: 0, 1, 2, 3
WARNING:tensorflow:From /HOME/scz1075/.conda/envs/kungfu/lib/python3.9/site-packages/tensorflow/python/keras/layers/normalization.py:534: _colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.
Instructions for updating:
Colocations handled automatically by placer.
W1015 10:09:18.457707 47349325168000 deprecation.py:330] From /HOME/scz1075/.conda/envs/kungfu/lib/python3.9/site-packages/tensorflow/python/keras/layers/normalization.py:534: _colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.
Instructions for updating:
Colocations handled automatically by placer.
TensorFlow:  2.5
Model:       resnet50
Dataset:     imagenet (synthetic)
Mode:        BenchmarkMode.TRAIN
SingleSess:  False
Batch size:  160 global
             40.0 per device
Num batches: 100
Num epochs:  0.01
Devices:     ['/gpu:0', '/gpu:1', '/gpu:2', '/gpu:3']
Data format: NCHW
Optimizer:   sgd
Variables:   parameter_server
==========
Generating training model
shapes: self.top_layer: [40, 3, 224, 224]
shapes: network.top_layer 1: [40, 3, 224, 224]
shapes: network.top_layer 2: [40, 3, 224, 224]
cnn.top_layer.shape: [40, 64, 56, 256]
cnn.top_layer.shape: [40, 64, 56, 256]
cnn.top_layer.shape: [40, 64, 56, 256]
cnn.top_layer.shape: [40, 32, 28, 512]
cnn.top_layer.shape: [40, 32, 28, 512]
cnn.top_layer.shape: [40, 32, 28, 512]
cnn.top_layer.shape: [40, 32, 28, 512]
cnn.top_layer.shape: [40, 16, 14, 1024]
cnn.top_layer.shape: [40, 16, 14, 1024]
cnn.top_layer.shape: [40, 16, 14, 1024]
cnn.top_layer.shape: [40, 16, 14, 1024]
cnn.top_layer.shape: [40, 16, 14, 1024]
cnn.top_layer.shape: [40, 16, 14, 1024]
cnn.top_layer.shape: [40, 8, 7, 2048]
cnn.top_layer.shape: [40, 8, 7, 2048]
cnn.top_layer.shape: [40, 8, 7, 2048]
shape: cnn.top_layer 11: [40, 8, 7, 2048]
shape: self.top_layer 0000: [40, 8, 7, 2048]
shape: self.top_layer 1111: [40, 8]
shapes: network.top_layer 3: [40, 8]
shapes: self.top_layer: [40, 3, 224, 224]
shapes: network.top_layer 1: [40, 3, 224, 224]
shapes: network.top_layer 2: [40, 3, 224, 224]
cnn.top_layer.shape: [40, 64, 56, 256]
cnn.top_layer.shape: [40, 64, 56, 256]
cnn.top_layer.shape: [40, 64, 56, 256]
cnn.top_layer.shape: [40, 32, 28, 512]
cnn.top_layer.shape: [40, 32, 28, 512]
cnn.top_layer.shape: [40, 32, 28, 512]
cnn.top_layer.shape: [40, 32, 28, 512]
cnn.top_layer.shape: [40, 16, 14, 1024]
cnn.top_layer.shape: [40, 16, 14, 1024]
cnn.top_layer.shape: [40, 16, 14, 1024]
cnn.top_layer.shape: [40, 16, 14, 1024]
cnn.top_layer.shape: [40, 16, 14, 1024]
cnn.top_layer.shape: [40, 16, 14, 1024]
cnn.top_layer.shape: [40, 8, 7, 2048]
cnn.top_layer.shape: [40, 8, 7, 2048]
cnn.top_layer.shape: [40, 8, 7, 2048]
shape: cnn.top_layer 11: [40, 8, 7, 2048]
shape: self.top_layer 0000: [40, 8, 7, 2048]
shape: self.top_layer 1111: [40, 8]
shapes: network.top_layer 3: [40, 8]
shapes: self.top_layer: [40, 3, 224, 224]
shapes: network.top_layer 1: [40, 3, 224, 224]
shapes: network.top_layer 2: [40, 3, 224, 224]
cnn.top_layer.shape: [40, 64, 56, 256]
cnn.top_layer.shape: [40, 64, 56, 256]
cnn.top_layer.shape: [40, 64, 56, 256]
cnn.top_layer.shape: [40, 32, 28, 512]
cnn.top_layer.shape: [40, 32, 28, 512]
cnn.top_layer.shape: [40, 32, 28, 512]
cnn.top_layer.shape: [40, 32, 28, 512]
cnn.top_layer.shape: [40, 16, 14, 1024]
cnn.top_layer.shape: [40, 16, 14, 1024]
cnn.top_layer.shape: [40, 16, 14, 1024]
cnn.top_layer.shape: [40, 16, 14, 1024]
cnn.top_layer.shape: [40, 16, 14, 1024]
cnn.top_layer.shape: [40, 16, 14, 1024]
cnn.top_layer.shape: [40, 8, 7, 2048]
cnn.top_layer.shape: [40, 8, 7, 2048]
cnn.top_layer.shape: [40, 8, 7, 2048]
shape: cnn.top_layer 11: [40, 8, 7, 2048]
shape: self.top_layer 0000: [40, 8, 7, 2048]
shape: self.top_layer 1111: [40, 8]
shapes: network.top_layer 3: [40, 8]
shapes: self.top_layer: [40, 3, 224, 224]
shapes: network.top_layer 1: [40, 3, 224, 224]
shapes: network.top_layer 2: [40, 3, 224, 224]
cnn.top_layer.shape: [40, 64, 56, 256]
cnn.top_layer.shape: [40, 64, 56, 256]
cnn.top_layer.shape: [40, 64, 56, 256]
cnn.top_layer.shape: [40, 32, 28, 512]
cnn.top_layer.shape: [40, 32, 28, 512]
cnn.top_layer.shape: [40, 32, 28, 512]
cnn.top_layer.shape: [40, 32, 28, 512]
cnn.top_layer.shape: [40, 16, 14, 1024]
cnn.top_layer.shape: [40, 16, 14, 1024]
cnn.top_layer.shape: [40, 16, 14, 1024]
cnn.top_layer.shape: [40, 16, 14, 1024]
cnn.top_layer.shape: [40, 16, 14, 1024]
cnn.top_layer.shape: [40, 16, 14, 1024]
cnn.top_layer.shape: [40, 8, 7, 2048]
cnn.top_layer.shape: [40, 8, 7, 2048]
cnn.top_layer.shape: [40, 8, 7, 2048]
shape: cnn.top_layer 11: [40, 8, 7, 2048]
shape: self.top_layer 0000: [40, 8, 7, 2048]
shape: self.top_layer 1111: [40, 8]
shapes: network.top_layer 3: [40, 8]
Traceback (most recent call last):
  File "/data/run01/scz1075/kf-benchmarks/scripts/tf_cnn_benchmarks/tf_cnn_benchmarks.py", line 64, in <module>
    app.run(main)  # Raises error on invalid flags, unlike tf.app.run()
  File "/HOME/scz1075/.conda/envs/kungfu/lib/python3.9/site-packages/absl/app.py", line 312, in run
    _run_main(main, args)
  File "/HOME/scz1075/.conda/envs/kungfu/lib/python3.9/site-packages/absl/app.py", line 258, in _run_main
    sys.exit(main(argv))
  File "/data/run01/scz1075/kf-benchmarks/scripts/tf_cnn_benchmarks/tf_cnn_benchmarks.py", line 56, in main
    bench.run()
  File "/data/run01/scz1075/kf-benchmarks/scripts/tf_cnn_benchmarks/benchmark_cnn.py", line 1755, in run
    return self._benchmark_train()
  File "/data/run01/scz1075/kf-benchmarks/scripts/tf_cnn_benchmarks/benchmark_cnn.py", line 1934, in _benchmark_train
    build_result = self._build_graph()
  File "/data/run01/scz1075/kf-benchmarks/scripts/tf_cnn_benchmarks/benchmark_cnn.py", line 1968, in _build_graph
    (input_producer_op, enqueue_ops, fetches) = self._build_model()
  File "/data/run01/scz1075/kf-benchmarks/scripts/tf_cnn_benchmarks/benchmark_cnn.py", line 2728, in _build_model
    fetches = self._build_fetches(global_step, all_logits, losses, device_grads,
  File "/data/run01/scz1075/kf-benchmarks/scripts/tf_cnn_benchmarks/benchmark_cnn.py", line 2778, in _build_fetches
    avg_grads = self.variable_mgr.get_gradients_to_apply(d,
  File "/data/run01/scz1075/kf-benchmarks/scripts/tf_cnn_benchmarks/variable_mgr.py", line 223, in get_gradients_to_apply
    variable_mgr_util.
  File "/data/run01/scz1075/kf-benchmarks/scripts/tf_cnn_benchmarks/variable_mgr_util.py", line 458, in aggregate_gradients_using_copy_with_variable_colocation
    grad_and_var, has_nan_or_inf = aggregate_single_gradient_using_copy(
  File "/data/run01/scz1075/kf-benchmarks/scripts/tf_cnn_benchmarks/variable_mgr_util.py", line 524, in aggregate_single_gradient_using_copy
    grad = tf.add_n(grads)
  File "/HOME/scz1075/.conda/envs/kungfu/lib/python3.9/site-packages/tensorflow/python/util/dispatch.py", line 206, in wrapper
    return target(*args, **kwargs)
  File "/HOME/scz1075/.conda/envs/kungfu/lib/python3.9/site-packages/tensorflow/python/ops/math_ops.py", line 3743, in add_n
    raise ValueError("inputs must be an iterable of at least one "
ValueError: inputs must be an iterable of at least one Tensor/IndexedSlices with the same dtype and shape
